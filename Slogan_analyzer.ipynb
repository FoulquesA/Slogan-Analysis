

"""
Slogan Effectiveness Analyzer
==============================

Comprehensive analysis framework for marketing slogans using NLP, sentiment analysis,
and machine learning clustering to score and evaluate slogan effectiveness.

"""


import re
import time
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Optional

# Web scraping
import requests
from bs4 import BeautifulSoup

# NLP & Sentiment Analysis
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import spacy

# Machine Learning
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans


# =============================================================================
# CONFIGURATION & CONSTANTS
# =============================================================================

CATEGORIES = [
    'drinking-slogans', 'food-slogans', 'restaurant-slogans', 'car-slogan',
    'apparel-slogans', 'technology-slogans', 'business-slogans', 'company-slogans',
    'cosmetics-slogans', 'household-slogans', 'financial-slogans', 'tours-slogans',
    'airlines-slogans', 'television-channels-slogan', 'health-medicine-slogans',
    'sports-games-slogans', 'education-slogans', 'campaign-slogans', 'uncategorized'
]

POWER_VERBS = [
    'make', 'create', 'build', 'discover', 'explore', 'get',
    'find', 'start', 'go', 'do', 'think', 'imagine', 'love'
]

MARKETING_CLICHES = {
    # Superlatives
    'best': 3, 'better': 2, 'ultimate': 3, 'perfect': 3, 'premier': 3,
    'leading': 3, 'top': 2, 'number one': 3, '#1': 3,
    # Innovation buzzwords
    'innovative': 3, 'innovation': 3, 'cutting edge': 3, 'cutting-edge': 3,
    'revolutionary': 3, 'breakthrough': 3, 'next generation': 3,
    'state of the art': 3, 'advanced': 2, 'smart': 2, 'new': 1,
    # Quality claims
    'quality': 3, 'excellence': 3, 'premium': 2, 'superior': 3,
    'finest': 3, 'exceptional': 2,
    # Business speak
    'solutions': 3, 'solution': 3, 'trusted': 3, 'trust': 2,
    'leader': 3, 'leadership': 3, 'world class': 3, 'world-class': 3,
    'global': 2, 'international': 2,
    # Vague promises
    'experience': 2, 'value': 2, 'choice': 1, 'difference': 2,
    'expert': 2, 'professional': 2, 'authentic': 2, 'real': 1,
    'original': 2, 'unique': 2,
}

EFFECTIVENESS_WEIGHTS = {
    'score_length': 0.15,
    'score_memorability': 0.25,
    'score_emotion': 0.20,
    'score_action': 0.15,
    'score_originality': 0.15,
    'score_personal': 0.10
}


# =============================================================================
# 1. DATA COLLECTION
# =============================================================================

def scrape_slogans(base_url: str = "https://www.sloganlist.com/") -> pd.DataFrame:
    """
    Scrape slogans from sloganlist.com across all categories.

    Returns
    -------
    pd.DataFrame
        DataFrame with columns: Company, Slogan, Category
    """
    all_slogans = []

    for category in CATEGORIES:

        # Get first page to determine total pages
        url = f"{base_url}{category}/"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')

        max_page = _get_max_page(soup)
        print(f"  Found {max_page} pages")

        # Scrape all pages
        for page in range(1, max_page + 1):
            page_url = url if page == 1 else f"{base_url}{category}/index_{page}.html"

            try:
                page_slogans = _scrape_page(page_url, category)
                all_slogans.extend(page_slogans)
                print(f"    Page {page}: {len(page_slogans)} slogans")
                time.sleep(0.5)  # Be polite to the server
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Error on page {page}: {e}")

    # Create DataFrame and remove duplicates
    df = pd.DataFrame(all_slogans)
    df = df.drop_duplicates()

    return df


def _get_max_page(soup: BeautifulSoup) -> int:
    """Extract maximum page number from pagination links."""
    max_page = 1
    for link in soup.find_all('a', href=True):
        href = link['href']
        if 'index_' in href and '.html' in href:
            try:
                page_num = int(href.split('index_')[1].split('.html')[0])
                max_page = max(max_page, page_num)
            except ValueError:
                continue
    return max_page


def _scrape_page(url: str, category: str) -> List[Dict]:
    """Scrape all slogans from a single page."""
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    links = soup.find_all('a', href=lambda x: x and (
        x.endswith('-slogan.html') or x.endswith('-slogans.html')
    ))

    slogans = []
    for link in links:
        text = link.get_text()
        if '- ' in text:
            parts = text.split('- ', 1)
            slogans.append({
                'Company': parts[0].strip(),
                'Slogan': parts[1].strip(),
                'Category': category
            })

    return slogans


# =============================================================================
# 2. DATA CLEANING
# =============================================================================

def clean_data(df: pd.DataFrame) -> pd.DataFrame:
   
    initial_count = len(df)

    # Remove rows with missing values
    df = df.dropna()

    # Ensure Slogan column is string type
    df['Slogan'] = df['Slogan'].astype(str)

    # Remove empty slogans
    df = df[df['Slogan'].str.len() > 0]

    final_count = len(df)
    removed = initial_count - final_count

    print(f"  Removed {removed} rows with missing/empty data")
    print(f"  Final dataset: {final_count} slogans")

    return df


# =============================================================================
# 3. BASIC METRICS
# =============================================================================

def add_basic_metrics(df: pd.DataFrame) -> pd.DataFrame:

    df['char_count'] = df['Slogan'].str.len()
    df['word_count'] = df['Slogan'].str.split().str.len()

    return df


# =============================================================================
# 4. SENTIMENT ANALYSIS
# =============================================================================

def add_sentiment_analysis(df: pd.DataFrame) -> pd.DataFrame:

    vader = SentimentIntensityAnalyzer()

    # VADER sentiment score
    df['sentiment_score'] = df['Slogan'].apply(
        lambda x: vader.polarity_scores(str(x))['compound']
    )

    # Classify sentiment
    df['sentiment'] = df['sentiment_score'].apply(_classify_sentiment)

    # TextBlob subjectivity
    df['subjectivity'] = df['Slogan'].apply(
        lambda x: TextBlob(str(x)).sentiment.subjectivity
    )

    return df


def _classify_sentiment(score: float) -> str:
    """Classify sentiment score into Positive/Neutral/Negative."""
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'


# =============================================================================
# 5. EFFECTIVENESS SCORES
# =============================================================================

def score_length(slogan: str) -> float:
    
    if pd.isna(slogan) or not isinstance(slogan, str):
        return 5.0

    word_count = len(slogan.split())
    char_count = len(slogan)

    # Score based on word count (optimal: 3-6 words)
    if 3 <= word_count <= 6:
        word_score = 10
    elif 2 <= word_count <= 8:
        word_score = 7
    else:
        word_score = max(0, 10 - abs(word_count - 4.5))

    # Score based on character count (optimal: 20-40 chars)
    if 20 <= char_count <= 40:
        char_score = 10
    elif 15 <= char_count <= 50:
        char_score = 7
    else:
        char_score = max(0, 10 - abs(char_count - 30) / 5)

    return (word_score + char_score) / 2


def score_memorability(slogan: str) -> float:
   
    if pd.isna(slogan) or not isinstance(slogan, str) or len(slogan) == 0:
        return 0

    words = slogan.lower().split()
    if len(words) == 0:
        return 0

    score = 0

    # Alliteration (same first letter)
    if len(words) >= 2:
        first_letters = [w[0] for w in words if len(w) > 0]
        if len(set(first_letters)) < len(first_letters):
            score += 3

    # Rhyme (same ending)
    if len(words) >= 2:
        endings = [w[-2:] for w in words if len(w) >= 2]
        if len(set(endings)) < len(endings):
            score += 3

    # Rhythm (similar syllable count)
    syllables = [len(re.findall(r'[aeiou]+', w.lower())) for w in words]
    if len(syllables) >= 2 and max(syllables) - min(syllables) <= 1:
        score += 2

    # Word repetition
    if len(words) != len(set(words)):
        score += 2

    return min(score, 10)


def score_emotional_impact(row: pd.Series) -> float:
   
    sentiment = abs(row['sentiment_score'])
    subjectivity = row['subjectivity']

    emotion_score = (sentiment * 5 + subjectivity * 5)

    # Bonus for very positive sentiment
    if row['sentiment_score'] > 0.5:
        emotion_score += 2

    return min(emotion_score, 10)


def score_action(slogan: str, nlp) -> float:
   
    if pd.isna(slogan) or not isinstance(slogan, str):
        return 0

    doc = nlp(slogan.lower())
    verbs = [token for token in doc if token.pos_ == 'VERB']

    score = 0

    # Has verb
    if len(verbs) > 0:
        score += 5

    # Has power verb
    if any(v.lemma_ in POWER_VERBS for v in verbs):
        score += 3

    # Starts with verb (imperative)
    if len(doc) > 0 and doc[0].pos_ == 'VERB':
        score += 2

    return min(score, 10)


def score_personal_engagement(slogan: str) -> float:
    
    if pd.isna(slogan) or not isinstance(slogan, str):
        return 0

    slogan_lower = slogan.lower()
    score = 0

    # You/your (direct engagement)
    if 'you' in slogan_lower or 'your' in slogan_lower:
        score += 5

    # We/our (inclusive engagement)
    if 'we' in slogan_lower or 'our' in slogan_lower:
        score += 3

    return min(score, 10)


def score_originality(slogan: str) -> float:
   
    if pd.isna(slogan) or not isinstance(slogan, str) or len(slogan) == 0:
        return 5.0

    slogan_lower = slogan.lower()
    penalty = 0

    for cliche, points in MARKETING_CLICHES.items():
        if cliche in slogan_lower:
            penalty += points

    return max(0, 10 - penalty)


def detect_cliches(slogan: str) -> List[str]:
   
    if pd.isna(slogan) or not isinstance(slogan, str) or len(slogan) == 0:
        return []

    slogan_lower = slogan.lower()
    return [cliche for cliche in MARKETING_CLICHES.keys() if cliche in slogan_lower]


def add_all_scores(df: pd.DataFrame) -> pd.DataFrame:

    # Load spaCy model
    try:
        nlp = spacy.load('en_core_web_sm')
    except OSError:
        import os
        os.system('python -m spacy download en_core_web_sm')
        nlp = spacy.load('en_core_web_sm')

    # Compute scores
    df['score_length'] = df['Slogan'].apply(score_length)
    df['score_memorability'] = df['Slogan'].apply(score_memorability)
    df['score_emotion'] = df.apply(score_emotional_impact, axis=1)
    df['score_action'] = df['Slogan'].apply(lambda x: score_action(x, nlp))
    df['score_personal'] = df['Slogan'].apply(score_personal_engagement)
    df['score_originality'] = df['Slogan'].apply(score_originality)

    # Detect clich√©s
    df['cliches_detected'] = df['Slogan'].apply(detect_cliches)
    df['cliche_count'] = df['cliches_detected'].apply(len)

    return df


# =============================================================================
# 6. THEMATIC CLUSTERING
# =============================================================================

def perform_clustering(df: pd.DataFrame, n_clusters: int = 10) -> pd.DataFrame:

    # Clean dataset (remove empty slogans)
    df_clean = df[df['Slogan'].notna() & (df['Slogan'].str.len() > 0)].copy()

    # TF-IDF vectorization
    vectorizer = TfidfVectorizer(
        max_features=100,
        stop_words='english',
        ngram_range=(1, 2),
        min_df=5
    )
    X = vectorizer.fit_transform(df_clean['Slogan'])

    # K-Means clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df_clean['theme_cluster'] = kmeans.fit_predict(X)

    # Extract keywords per cluster
    feature_names = vectorizer.get_feature_names_out()
    cluster_info = {}

    for i in range(n_clusters):
        cluster_center = kmeans.cluster_centers_[i]
        top_indices = cluster_center.argsort()[-8:][::-1]
        top_words = [feature_names[idx] for idx in top_indices]
        cluster_info[i] = top_words

    # Assign unique titles
    cluster_titles = _assign_unique_cluster_titles(cluster_info)

    # Add cluster info to main DataFrame
    df['theme_cluster'] = -1
    df.loc[df_clean.index, 'theme_cluster'] = df_clean['theme_cluster']
    df['theme_title'] = df['theme_cluster'].map(
        lambda x: cluster_titles.get(x, 'Unclassified') if x != -1 else 'Unclassified'
    )
    df['theme_keywords'] = df['theme_cluster'].map(
        lambda x: ', '.join(cluster_info[x][:3]) if x != -1 else ''
    )

    return df


def _assign_unique_cluster_titles(clusters_data: Dict[int, List[str]]) -> Dict[int, str]:
    """Assign unique descriptive titles to each cluster based on keywords."""
    used_titles = set()
    cluster_titles = {}

    for cluster_id, top_words in clusters_data.items():
        words_set = set(w.lower() for w in top_words)

        # Define possible titles based on keyword patterns
        possible_titles = []

        if 'love' in words_set or 'passion' in words_set:
            possible_titles.extend(["Love & Passion", "Emotional Connection"])
        if 'feel' in words_set:
            possible_titles.extend(["Feelings & Sensations", "Sensory Experience"])
        if 'great' in words_set and 'good' in words_set:
            possible_titles.extend(["Satisfaction & Pleasure"])
        elif 'good' in words_set:
            possible_titles.extend(["Quality & Goodness"])
        elif 'great' in words_set:
            possible_titles.extend(["Greatness & Excellence"])
        if 'best' in words_set or 'better' in words_set:
            possible_titles.extend(["Superiority", "Leadership"])
        if 'world' in words_set:
            possible_titles.extend(["Global Dimension", "Worldwide Reach"])
        if 'new' in words_set or 'innovation' in words_set:
            possible_titles.extend(["Innovation & Novelty", "Modernity"])
        if 'make' in words_set or 'made' in words_set:
            possible_titles.extend(["Creation & Making", "Craftsmanship"])
        if 'live' in words_set or 'life' in words_set:
            possible_titles.extend(["Lifestyle", "Living Experience"])
        if 'time' in words_set:
            possible_titles.extend(["Time & Moments"])
        if 'taste' in words_set or 'fresh' in words_set:
            possible_titles.extend(["Taste & Freshness", "Flavor"])
        if 'easy' in words_set or 'simply' in words_set:
            possible_titles.extend(["Simplicity & Ease"])
        if 'people' in words_set:
            possible_titles.extend(["Human Connection", "Community"])

        # Fallback: create title from top words
        if not possible_titles:
            if len(top_words) >= 2:
                possible_titles.append(f"{top_words[0].capitalize()} & {top_words[1].capitalize()}")
            else:
                possible_titles.append(f"Theme {cluster_id}")

        # Find first unused title
        assigned_title = None
        for title in possible_titles:
            if title not in used_titles:
                assigned_title = title
                used_titles.add(title)
                break

        # If all titles used, add cluster ID
        if assigned_title is None:
            assigned_title = f"{possible_titles[0]} ({cluster_id})"
            used_titles.add(assigned_title)

        cluster_titles[cluster_id] = assigned_title

    return cluster_titles


# =============================================================================
# 7. COMPOSITE EFFECTIVENESS SCORE
# =============================================================================

def calculate_effectiveness_score(df: pd.DataFrame,
                                  weights: Optional[Dict[str, float]] = None) -> pd.DataFrame:

    if weights is None:
        weights = EFFECTIVENESS_WEIGHTS

    # Ensure all score columns exist (fill with neutral value if missing)
    for col in weights.keys():
        if col not in df.columns:
            df[col] = 5.0

    # Calculate weighted average
    df['effectiveness_score'] = sum(
        df[col].fillna(5) * weight for col, weight in weights.items()
    )

    # Normalize to 0-10
    df['effectiveness_score'] = df['effectiveness_score'].clip(0, 10)

    # Categorize
    df['effectiveness_category'] = df['effectiveness_score'].apply(_categorize_effectiveness)

    return df


def _categorize_effectiveness(score: float) -> str:
    """Categorize effectiveness score into qualitative labels."""
    if score >= 8:
        return "Excellent"
    elif score >= 6.5:
        return "Very Good"
    elif score >= 5:
        return "Good"
    elif score >= 3.5:
        return "Average"
    else:
        return "Weak"


# =============================================================================
# 8. ANALYSIS & REPORTING
# =============================================================================

def generate_summary_statistics(df: pd.DataFrame) -> Dict:
   
    return {
        'total_slogans': len(df),
        'categories': df['Category'].nunique(),
        'avg_effectiveness': df['effectiveness_score'].mean(),
        'median_effectiveness': df['effectiveness_score'].median(),
        'excellent_count': sum(df['effectiveness_score'] >= 8),
        'excellent_pct': sum(df['effectiveness_score'] >= 8) / len(df) * 100,
        'avg_length_words': df['word_count'].mean(),
        'avg_length_chars': df['char_count'].mean(),
        'sentiment_positive_pct': sum(df['sentiment'] == 'Positive') / len(df) * 100,
        'sentiment_neutral_pct': sum(df['sentiment'] == 'Neutral') / len(df) * 100,
        'sentiment_negative_pct': sum(df['sentiment'] == 'Negative') / len(df) * 100,
        'top_category': df.groupby('Category')['effectiveness_score'].mean().idxmax(),
    }


def print_analysis_report(df: pd.DataFrame, stats: Dict):
   
    print("\n" + "="*80)
    print("üìä SLOGAN EFFECTIVENESS ANALYSIS - SUMMARY REPORT")
    print("="*80)

    print(f"\nüìà DATASET OVERVIEW")
    print(f"  Total slogans analyzed: {stats['total_slogans']:,}")
    print(f"  Number of categories: {stats['categories']}")

    print(f"\n‚≠ê EFFECTIVENESS SCORES")
    print(f"  Average score: {stats['avg_effectiveness']:.2f}/10")
    print(f"  Median score: {stats['median_effectiveness']:.2f}/10")
    print(f"  Excellent slogans (‚â•8/10): {stats['excellent_count']} ({stats['excellent_pct']:.1f}%)")

    print(f"\nüìè LENGTH STATISTICS")
    print(f"  Average words: {stats['avg_length_words']:.1f}")
    print(f"  Average characters: {stats['avg_length_chars']:.1f}")

    print(f"\nüí≠ SENTIMENT DISTRIBUTION")
    print(f"  Positive: {stats['sentiment_positive_pct']:.1f}%")
    print(f"  Neutral: {stats['sentiment_neutral_pct']:.1f}%")
    print(f"  Negative: {stats['sentiment_negative_pct']:.1f}%")

    print(f"\nüèÖ TOP PERFORMING CATEGORY")
    print(f"  {stats['top_category']}")

    # Top 10 slogans
    print("\n" + "="*80)
    print("üèÜ TOP 10 MOST EFFECTIVE SLOGANS")
    print("="*80)

    top_10 = df.nlargest(10, 'effectiveness_score')[
        ['Company', 'Slogan', 'effectiveness_score', 'Category']
    ]

    for idx, row in top_10.iterrows():
        print(f"\n{row['effectiveness_score']:.2f}/10 - {row['Company']}")
        print(f"  \"{row['Slogan']}\"")
        print(f"  Category: {row['Category']}")

    print("\n" + "="*80)


def save_results(df: pd.DataFrame, output_path: str = 'slogans_analyzed.csv'):
  
    # Select key columns for output
    output_df = df[[
        'Company', 'Slogan', 'Category',
        'effectiveness_score', 'effectiveness_category',
        'sentiment_score', 'sentiment', 'subjectivity',
        'score_length', 'score_memorability', 'score_emotion',
        'score_action', 'score_originality', 'score_personal',
        'char_count', 'word_count',
        'theme_cluster', 'theme_title', 'theme_keywords',
        'cliches_detected', 'cliche_count'
    ]].copy()

    output_df = output_df.sort_values('effectiveness_score', ascending=False)
    output_df.to_csv(output_path, index=False, encoding='utf-8')



# =============================================================================
# 9. MAIN PIPELINE
# =============================================================================

def analyze_slogans(scrape_new_data: bool = False,
                   data_path: str = 'all_slogans.csv',
                   output_path: str = 'slogans_analyzed.csv') -> pd.DataFrame:
   
    print("\n" + "="*80)

    print("="*80)

    # Step 1: Get data
    if scrape_new_data:
        df = scrape_slogans()
        df.to_csv(data_path, index=False, encoding='utf-8')
    else:
        print(f"\nüìÇ Loading data from {data_path}...")
        df = pd.read_csv(data_path)

    # Step 2: Clean data
    df = clean_data(df)

    # Step 3: Basic metrics
    df = add_basic_metrics(df)

    # Step 4: Sentiment analysis
    df = add_sentiment_analysis(df)

    # Step 5: Effectiveness scores
    df = add_all_scores(df)

    # Step 6: Thematic clustering
    df = perform_clustering(df)

    # Step 7: Composite effectiveness score
    df = calculate_effectiveness_score(df)

    # Step 8: Analysis & reporting
    stats = generate_summary_statistics(df)
    print_analysis_report(df, stats)

    # Step 9: Save results
    save_results(df, output_path)

    print("="*80 + "\n")

    return df


# =============================================================================
# MAIN EXECUTION
# =============================================================================

if __name__ == "__main__":
    # Run full analysis
    df = analyze_slogans(
        scrape_new_data=True,  # Set to True to scrape fresh data
        data_path='all_slogans.csv',
        output_path='slogans_analyzed.csv'
    )

    # Optional: Display additional insights
    print("\nüìä Category Performance:")
    category_stats = df.groupby('Category')['effectiveness_score'].agg(['mean', 'count'])
    category_stats = category_stats.sort_values('mean', ascending=False)
    print(category_stats.head(10))

     
================================================================================
================================================================================
  Found 30 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 19 slogans
    Page 4: 20 slogans
    Page 5: 20 slogans
    Page 6: 20 slogans
    Page 7: 19 slogans
    Page 8: 20 slogans
    Page 9: 20 slogans
    Page 10: 20 slogans
    Page 11: 20 slogans
    Page 12: 20 slogans
    Page 13: 14 slogans
    Page 14: 15 slogans
    Page 15: 20 slogans
    Page 16: 18 slogans
    Page 17: 19 slogans
    Page 18: 19 slogans
    Page 19: 20 slogans
    Page 20: 19 slogans
    Page 21: 20 slogans
    Page 22: 20 slogans
    Page 23: 20 slogans
    Page 24: 20 slogans
    Page 25: 19 slogans
    Page 26: 20 slogans
    Page 27: 20 slogans
    Page 28: 20 slogans
    Page 29: 20 slogans
    Page 30: 19 slogans
  Found 20 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 20 slogans
    Page 4: 20 slogans
    Page 5: 7 slogans
    Page 6: 5 slogans
    Page 7: 20 slogans
    Page 8: 19 slogans
    Page 9: 19 slogans
    Page 10: 19 slogans
    Page 11: 19 slogans
    Page 12: 18 slogans
    Page 13: 20 slogans
    Page 14: 20 slogans
    Page 15: 20 slogans
    Page 16: 18 slogans
    Page 17: 20 slogans
    Page 18: 20 slogans
    Page 19: 20 slogans
    Page 20: 2 slogans
  Found 10 pages
    Page 1: 19 slogans
    Page 2: 20 slogans
    Page 3: 5 slogans
    Page 4: 19 slogans
    Page 5: 20 slogans
    Page 6: 20 slogans
    Page 7: 20 slogans
    Page 8: 20 slogans
    Page 9: 20 slogans
    Page 10: 8 slogans
  Found 8 pages
    Page 1: 20 slogans
    Page 2: 15 slogans
    Page 3: 20 slogans
    Page 4: 20 slogans
    Page 5: 20 slogans
    Page 6: 19 slogans
    Page 7: 20 slogans
    Page 8: 18 slogans
  Found 9 pages
    Page 1: 20 slogans
    Page 2: 10 slogans
    Page 3: 19 slogans
    Page 4: 20 slogans
    Page 5: 19 slogans
    Page 6: 20 slogans
    Page 7: 20 slogans
    Page 8: 20 slogans
    Page 9: 16 slogans
  Found 9 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 17 slogans
    Page 4: 7 slogans
    Page 5: 19 slogans
    Page 6: 20 slogans
    Page 7: 19 slogans
    Page 8: 20 slogans
    Page 9: 2 slogans
  Found 14 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 20 slogans
    Page 4: 20 slogans
    Page 5: 20 slogans
    Page 6: 19 slogans
    Page 7: 20 slogans
    Page 8: 20 slogans
    Page 9: 20 slogans
    Page 10: 20 slogans
    Page 11: 19 slogans
    Page 12: 20 slogans
    Page 13: 17 slogans
    Page 14: 9 slogans
  Found 38 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 20 slogans
    Page 4: 20 slogans
    Page 5: 20 slogans
    Page 6: 20 slogans
    Page 7: 20 slogans
    Page 8: 20 slogans
    Page 9: 16 slogans
    Page 10: 0 slogans
    Page 11: 0 slogans
    Page 12: 0 slogans
    Page 13: 0 slogans
    Page 14: 0 slogans
    Page 15: 2 slogans
    Page 16: 20 slogans
    Page 17: 20 slogans
    Page 18: 20 slogans
    Page 19: 20 slogans
    Page 20: 20 slogans
    Page 21: 20 slogans
    Page 22: 20 slogans
    Page 23: 20 slogans
    Page 24: 20 slogans
    Page 25: 20 slogans
    Page 26: 20 slogans
    Page 27: 20 slogans
    Page 28: 20 slogans
    Page 29: 19 slogans
    Page 30: 17 slogans
    Page 31: 20 slogans
    Page 32: 20 slogans
    Page 33: 20 slogans
    Page 34: 20 slogans
    Page 35: 20 slogans
    Page 36: 20 slogans
    Page 37: 19 slogans
    Page 38: 1 slogans
  Found 6 pages
    Page 1: 20 slogans
    Page 2: 7 slogans
    Page 3: 15 slogans
    Page 4: 19 slogans
    Page 5: 20 slogans
    Page 6: 18 slogans
  Found 5 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 17 slogans
    Page 4: 20 slogans
    Page 5: 18 slogans
  Found 11 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 6 slogans
    Page 4: 0 slogans
    Page 5: 14 slogans
    Page 6: 19 slogans
    Page 7: 20 slogans
    Page 8: 20 slogans
    Page 9: 20 slogans
    Page 10: 19 slogans
    Page 11: 4 slogans
  Found 11 pages
    Page 1: 20 slogans
    Page 2: 19 slogans
    Page 3: 20 slogans
    Page 4: 18 slogans
    Page 5: 19 slogans
    Page 6: 17 slogans
    Page 7: 19 slogans
    Page 8: 20 slogans
    Page 9: 20 slogans
    Page 10: 20 slogans
    Page 11: 3 slogans
  Found 8 pages
    Page 1: 19 slogans
    Page 2: 14 slogans
    Page 3: 19 slogans
    Page 4: 20 slogans
    Page 5: 20 slogans
    Page 6: 20 slogans
    Page 7: 20 slogans
    Page 8: 7 slogans
  Found 3 pages
    Page 1: 19 slogans
    Page 2: 20 slogans
    Page 3: 12 slogans
  Found 1 pages
    Page 1: 5 slogans
  Found 3 pages
    Page 1: 20 slogans
    Page 2: 20 slogans
    Page 3: 12 slogans
  Found 1 pages
    Page 1: 14 slogans
  Found 1 pages
    Page 1: 11 slogans
  Found 5 pages
    Page 1: 18 slogans
    Page 2: 13 slogans
    Page 3: 20 slogans
    Page 4: 19 slogans
    Page 5: 11 slogans
  Removed 1 rows with missing/empty data
  Final dataset: 3338 slogans

================================================================================
üìä SLOGAN EFFECTIVENESS ANALYSIS - SUMMARY REPORT
================================================================================

üìà DATASET OVERVIEW
  Total slogans analyzed: 3,338
  Number of categories: 19

‚≠ê EFFECTIVENESS SCORES
  Average score: 4.67/10
  Median score: 4.57/10
  Excellent slogans (‚â•8/10): 11 (0.3%)

üìè LENGTH STATISTICS
  Average words: 3.9
  Average characters: 21.7

üí≠ SENTIMENT DISTRIBUTION
  Positive: 39.7%
  Neutral: 56.1%
  Negative: 4.2%

üèÖ TOP PERFORMING CATEGORY
  health-medicine-slogans

================================================================================
üèÜ TOP 10 MOST EFFECTIVE SLOGANS
================================================================================

8.78/10 - Dettol
  "We Protect What We Love"
  Category: household-slogans

8.76/10 - Cornetto
  "Enjoy the ride, love the ending"
  Category: food-slogans

8.76/10 - Estee Lauder
  "Enjoy the stay. Love the shine."
  Category: cosmetics-slogans

8.64/10 - eBay
  "Buy it. Sell it. Love it."
  Category: technology-slogans

8.47/10 - Pep boys
  "Cars like us. People love us."
  Category: company-slogans

8.36/10 - Cuprinol
  "Make your garden great!"
  Category: household-slogans

8.32/10 - Old Milwaukee
  "Taste as great as it's name."
  Category: drinking-slogans

8.25/10 - Peaches Uniforms
  "Designed for fit. Loved for style."
  Category: uncategorized

8.21/10 - Louis Vuitton
  "Live and love the truth"
  Category: apparel-slogans

8.05/10 - Moores
  "Well made, Well Priced, Well Dressed"
  Category: apparel-slogans

================================================================================
================================================================================


üìä Category Performance:
                             mean  count
Category                                
health-medicine-slogans  5.311660      5
education-slogans        5.110131     14
cosmetics-slogans        5.056578     99
household-slogans        5.046863     95
restaurant-slogans       4.927464    171
food-slogans             4.911700    346
campaign-slogans         4.755395     11
airlines-slogans         4.748712    139
business-slogans         4.731803    264
uncategorized            4.706312     81
